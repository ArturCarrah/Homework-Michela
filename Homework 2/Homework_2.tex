\documentclass[a4paper,11pt]{article}

\usepackage[portuguese]{babel} %Caracteres do português
\usepackage[T1]{fontenc}       %Fonte
\usepackage{amsmath, amssymb}  %Fórmulas matemáticas
\usepackage{graphicx}          %Imagens
\usepackage{color}             %Cores nas letras
\usepackage{listings}          %Códigos de linguagens de programação
\usepackage{setspace}          %Espaçamento dos parágrafos
\usepackage{hyperref}
\usepackage{subcaption}        %Para colocar 2 imagens lado a lado

\oddsidemargin 0.22in
\textwidth 5.8in

% Ajuste no título da seção para garantir que a numeração apareça
\usepackage[explicit]{titlesec}
\titleformat{\section}[block]{\normalfont\Large\scshape}{\thesection}{1em}{#1}  % Aqui a numeração aparece antes do título
\titleformat{\subsection}[block]{\normalfont\large\scshape}{\thesubsection}{1em}{#1}

\usepackage[title,titletoc]{appendix}
\AddToHook{env/appendices/begin}{
\titleformat{\section}{\normalfont\Large\scshape}{}{0em}{#1\ \thesection} % Formato correto para as seções no apêndice
}

\usepackage[skins]{tcolorbox}
\definecolor{bblue}{rgb}{0,0.3961,0.7412}
\usepackage[bookmarksnumbered=true]{hyperref} 
\hypersetup{
     colorlinks = true,
     linkcolor = bblue,
     anchorcolor = bblue,
     citecolor = bblue,
     filecolor = bblue,
     urlcolor = bblue
 }

\renewcommand{\lstlistingname}{Listado}
\lstset{
    backgroundcolor=\color[rgb]{0.86,0.88,0.93},
    language=R, keywordstyle=\color[rgb]{0,0,1},
    basicstyle=\footnotesize \ttfamily,breaklines=true,
    escapeinside={\%*}{*)}
}
\usepackage{footmisc} \renewcommand{\labelitemi}{$\circ$}
\usepackage{enumitem} \setlist[itemize]{leftmargin=*}

\usepackage{scrextend}
\deffootnote[1em]{1em}{1em}{\textsuperscript{\thefootnotemark}\,}
\begin{document}
\begin{figure}[!h] \includegraphics [scale=0.3] {Figures/Course-logo} \end{figure}
\begin{spacing}{1.5}

{\Large\sc \noindent \textbf{HOMEWORK 2}} \\
{\large\sc \noindent \textbf{Nome completo:} Lucas Teixeira Holanda / Artur Carrah Cerqueira}\\
{\large\sc \noindent \textbf{Número de matricula:} 568254 / 570754}

\end{spacing}
\vskip1cm



\section{\textbf{QUESTÃO 1 - RESTAURANTE}}
Em um restaurante muito frequentado, aproximadamente 70 por cento dos clientes pedem uma
sobremesa após o prato principal. Seja X a variável aleatória que representa o número de
clientes que pedem sobremesa em uma amostra aleatória de n = 50 clientes


\begin{enumerate}
\item Determine a função de distribuição de X.

\item Construa os gráficos da função massa de probabilidade (PMF) e da função distribuição
acumulada (CDF) de X.

\item Calcule o valor esperado, a variância e o desvio padrão de X.

\item Calcule a probabilidade de
\begin{enumerate}
  \item[(a)] P(X ≥ 20).

  \item[(b)] P(30 < X < 43).

  \item[(c)] P(X = 31).
\end{enumerate}

\item Suponha que o restaurante estoque sobremesas com base na demanda esperada. Como
o uso da distribuição de X poderia ajudar a reduzir desperdício e evitar falta de
produtos.

\item Como mudanças em p (por exemplo, sobremesa se torna mais popular, p = 0.8) ou em
n (número de clientes) afetariam a forma e as probabilidades de X.

\end{enumerate}

\newpage
\subsection{\textbf{SOLUÇÃO}}

\subsubsection{Item 1}
A variável aleatória X é o total de clients que pedem sobremesa em uma amostra aleatória de n = 50 clientes. Cada cliente pode fazer duas escolhas, pedir ou não pedir a sobremesa, ou seja, duas escolhas possíveis apenas. Considera-se que as escolhas são independentes e que as probabilidades de um cliente pedir uma sobremesa é \(\rho\) = 0.7, como foi fornecido pelo enunciado.

Como apenas duas escolhas são possíveis, usa-se da distribuição binomial para fornecer a função de distribuição de X: 
\[
X \sim \mathrm{Binomial}(n,\,p).
\]

A distribuição binomial é usado para descrever o número de sucessos em um número fixo de tentativas, quando cada tentativa tem a mesma probabilidade de sucesso. Como o número de clientes é fixo (n=50) e cada um é independentes do outro, com probabilidade \(\rho\) = 0.7 de pedir sobremesa, tem-se:

\[
X \sim \mathrm{Binomial}(50,\,0{,}7).
\]

Função de massa de probabilidade (PMF) da variável aleatória \(X\):
\[
P(X = k) = \binom{50}{k}(0{,}7)^k(0{,}3)^{50-k},
\quad k = 0, 1, 2, \ldots, 50.
\]
A PMF descreve a probabilidade de a variável aleatória discreta \(X\) assumir exatamente
o valor \(k\), isto é, a probabilidade de ocorrerem exatamente \(k\) sucessos em \(50\)
tentativas independentes, cada uma com probabilidade de sucesso igual a \(0{,}7\).

Função de distribuição acumulada (CDF) de \(X\): 
\[
F_X(x) = P(X \le x) = \sum_{k=0}^{\lfloor x \rfloor}
\binom{50}{k}(0{,}7)^k(0{,}3)^{50-k}
\]
A CDF representa a probabilidade
acumulada de a variável aleatória assumir valores menores ou iguais a \(x\), x pertence aos números reais, sendo obtida
pela soma das probabilidades associadas a todos os valores possíveis de \(X\) até esse
limite.

\subsubsection{Item 2}
Para construir os gráficos da PMF e da CDF é necessário entender cada uma delas, o que foi feito no item anterior, onde PMF fornece o valor probabilistico quando X assume um valor exato e CDF quando assume qualquer valor abaixo de um valor exato. Então assim, a CDF será um gráfico que começa do zero e vai subindo até alcançar a probabilidade = 1, enquanto o PMF pode assumir qualquer forma, sendo o intervalo das probabilidades entre 0 e 1.

Segue abaixo o código em R e os gráficos da PMF e da CDF: 
\begin{lstlisting}
# Distribuição binomial com n=50 e p=0.7
x <- 0:50

pmf = dbinom(x, 50, 0.7) # Função da PMF (51 valores, então pmf[1] = 0 e P(X = x) = pmf[x+1])       

plot(x,pmf,type='h',col='red',lwd=2, # Gráfico da PMF xlab= 'x', ylab='P(x)')

abline(h=0) # Adiciona uma linha no valor de P(x) = 0 para aumentar a legibilidade

cdf = c(0, cumsum(pmf)) # Calculando a CDF a partir da PMF

plot(cdf ,type='h',col='blue',lwd=2, # Gráfico da CDF xlab= 'x', ylab='P(X <= x)')

abline(h=0) # Adiciona uma linha no valor de P(x) = 0 para aumentar a legibilidade
\end{lstlisting}

\begin{figure}[h]

    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=0.9\linewidth, height=6cm]{PMF.JPG} 
        \caption{Gráfico da PMF}
        \label{fig:distp}
    \end{subfigure}
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=0.9\linewidth, height=6cm]{CDF.JPG}
        \caption{Gráfico da CDF}
        \label{fig:distb}
    \end{subfigure}
\label{fig:image2}
\end{figure}

 Veja no gráfico da PMF que os valores estão perto do 35 sucessos, o que fornece o valor estimado da nossa variável aleatória X. Enquanto na CDF, está mostrando exatamente o esperado, valores se acumulando até chegar em 1.

\subsubsection{Item 3}
O valor esperado, a variância e o desvio-padrão são dados importantes de se obter quando está tratando de uma distribuição de uma variável aleatória. Assim, neste item esses dados serão discutidos e calculados.

Para uma variável aleatória com distribuição binomial \(X \sim \mathrm{Binomial}(n,p)\), onde \textbf{n} corresponde ao número total de amostras e \textbf{p} a probabilidade de sucesso.
 O valor esperado corresponde ao número médio de sucessos em \(n\) tentativas, sendo dado por
\[
\mathbb{E}[X] = np.
\]
A variância mede a dispersão em torno dessa média e, para a distribuição binomial, é
\[
\mathrm{Var}(X) = np(1-p).
\]
O desvio-padrão, por sua vez, é definido como a raiz quadrada da variância:
\[
\sigma_ = \sqrt{\mathrm{Var}(X)} = \sqrt{np(1-p)}.
\]

No presente caso, com \(n = 50\) e \(p = 0{,}7\), obtém-se
\[
\mathbb{E}[X] = 50 \cdot 0{,}7 = 35,
\qquad
\mathrm{Var}(X) = 50 \cdot 0{,}7 \cdot 0{,}3 = 10{,}5,
\qquad
\sigma = \sqrt{10{,}5} \approx 3{,}24.
\]

Outro forma de calcular esses valores é usando um código em R. Dessa forma, segue abaixo o código usado isso e os seus resultados logo em seguida.

\begin{lstlisting}
x <- 0:50

# O valor esperado de uma distribuição binomial é n*p, nesse caso sendo 50*0.7 = 35.

Ex = weighted.mean(x, pmf) # O valor esperado é uma média ponderada usando as probabilidades de pesos
cat("Valor Esperado:", Ex, "\n")

# A variância de uma distribuição binomial é n*p*(1-p), nesse caso sendo 50*0.7*0.3 = 10.5
Var = Ex*0.3
dp = sqrt(Var)
cat("Variância:", Var, "\n")
cat("Desvio-Padrão:", sqrt(Var), "\n")
\end{lstlisting}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{dp.JPG}
    \caption{Valor esperado, variância e desvio-padrão}
\end{figure}

Note que os valores obtidos na Figura 2 estão iguais aos calculados teoricamente, o valida os dados obtidos.

\newpage
\subsubsection{Item 4}
Esse item explora o uso da PMF e da CDF para calcular diversos valores de probabilidades. Para isso, é possível usar uma função do R que faça o calculo de forma rápida.
\begin{enumerate}
  \item[(a)] \textbf{\(P(X \ge 20)\):}

  Essa probabilidade representa a chance de ocorrerem pelo menos \(20\) sucessos em
  \(50\) tentativas. Ela pode ser calculada somando-se as probabilidades de todos os
  valores de \(X\) maiores ou iguais a \(20\). De forma equivalente, pode-se utilizar a
  função de distribuição acumulada para escrever, sendo interessante seu uso para ecvitar de calcular diretamente diversas probabildades de forma individual.
  \[
  P(X \ge 20) = 1 - P(X \le 19) = 0.9999971 
  \]

  \item[(b)] \textbf{ \(P(30 < X < 43)\):}

  Nesse caso, deseja-se a probabilidade de que o número de sucessos esteja estritamente
  entre \(30\) e \(43\). Isso corresponde à soma das probabilidades associadas aos valores
  \(X = 31, 32, \ldots, 42\). Em termos da função de distribuição acumulada, essa
  probabilidade pode ser expressa como
  \[
  P(30 < X < 43) = P(X \le 42) - P(X \le 30) = 0.9079332 
  \]

  \item[(c)] \textbf{\(P(X = 31)\):}

  Essa probabilidade corresponde à chance de ocorrerem exatamente \(31\) sucessos em
  \(50\) tentativas. Ela é obtida diretamente a partir da função de massa de probabilidade
  da distribuição binomial, avaliando a PMF no ponto \(k = 31\).

  \[
P(X = 31) = \binom{50}{31}(0{,}7)^{31}(0{,}3)^{19} = 0.05575728 
\]
\end{enumerate}

Note que no item (a) o valor deu extremamente proximo de 1, o que está de acordo com o gráfico da CDF, onde a grande maioria dos valores estão acima de 20. O resultado do item (b) também é interessante, pois confirma a maior presença dos valores ao redor do valor esperado, sendo sua probabilidade maior que 0.9. Por fim, o item (c) também está de acordo com o gráfico da PMF mostrado anteriormente.

Abaixo segue o código em R usado para gerar esses valores:

\begin{lstlisting}
# Para X>=20:
s = 0
for(i in 21:50){
  s <- s + pmf[i]
}

cat("P(X >= 20):", s, "\n")

# Para 30 < X < 43:
s = 0
for(i in 32:43){
  s <- s + pmf[i]
}
cat("P(30 < X < 43):", s, "\n")

# Para X = 31:
cat("P(X = 31):", pmf[32], "\n")
\end{lstlisting}

\subsubsection{Item 5}
Com base na distribuição da variável aleatória \(X\), que modela o número de pedidos de sobremesa em um determinado período, o restaurante pode planejar seu estoque de forma mais eficiente, equilibrando disponibilidade e custo.

A partir dessa distribuição, calculam-se medidas como a média \(\mathbb{E}[X]\) e a variância \(\operatorname{Var}(X)\), que fornecem uma ideia não apenas da demanda esperada, mas também de sua variabilidade. Isso permite ajustar o estoque para cobrir a maior parte dos cenários prováveis.

Por exemplo, pode-se determinar:

\begin{itemize}
    \item \(P(X > k)\): probabilidade de a demanda ultrapassar certo nível \(k\) de estoque;
    \item \(P(X \leq k)\): probabilidade de a demanda ficar abaixo ou igual a \(k\).
\end{itemize}

Com esses valores, escolhe-se um estoque \(k^*\) que atenda a um nível desejado de serviço, minimizando tanto o risco de falta quanto o desperdício por excesso de produção.

Assim, o modelo probabilístico oferece uma base quantitativa para decisões de estoque, alinhando produção ao comportamento real da demanda.

\subsubsection{Item 6}
Alterações nos parâmetros \(p\) e \(n\) impactam diretamente o formato e as probabilidades da distribuição binomial associada à variável aleatória \(X\).

Se a probabilidade de sucesso \(p\) aumenta (como quando uma sobremesa fica mais popular, digamos \(p = 0{,}8\)), a média \(\mathbb{E}[X] = np\) também cresce. Isso desloca a distribuição para valores mais altos, indicando um número esperado maior de pedidos. Já a variância \(\operatorname{Var}(X) = np(1-p)\) pode subir ou descer conforme \(p\), mas tende a diminuir quando \(p\) se aproxima de 1, tornando a distribuição mais concentrada em torno da média.

Por outro lado, mudanças em \(n\)—o número de clientes—afetam tanto a posição quanto a dispersão da distribuição. Um aumento em \(n\) eleva a média e a variância proporcionalmente, tornando a curva mais espalhada, porém mais suave e simétrica, especialmente para \(n\) grande. Valores pequenos de \(n\) geram distribuições mais discretas e com maior variabilidade relativa.

Em resumo, quando \(p\) sobe, a probabilidade individual de pedido aumenta, deslocando a distribuição para a direita. Já quando \(n\) cresce, amplia-se a escala do cenário, afetando o total esperado de pedidos e sua dispersão. Entender esses efeitos é essencial para avaliar como mudanças no comportamento da clientela ou no volume de atendimento influenciam a demanda.







\newpage
\section{\textbf{QUESTÃO 2 - PESQUISA ONLINE}}
Um site realiza uma pesquisa online e oferece uma recompensa a um usuário selecionado aleatoriamente que responde a uma série de perguntas. Cada um dos 10 milhões de visitantes diários tem, independentemente, probabilidade $p = 10^{-7}$ de ganhar a recompensa.

\begin{enumerate} 
\item Encontre uma aproximação simples e adequada para a função de massa de probabilidade (PMF) do número de vencedores em um dia, X. Justifique claramente se essa aproximação é apropriada para os valores dados de $n$ e $p$
\item Calcule o valor esperado, E[X], e a variância Var(X), usando tanto a distribuição exata quanto a aproximada. Comente sobre a semelhança entre os resultados
\item Suponha que você ganhe a recompensa, mas que possa haver outros vencedores. Seja $W \sim Pois(1)$ o número de vencedores além de você. Se houver vários vencedores, o prêmio é sorteado aleatoriamente entre todos eles. Encontre a probabilidade de que você realmente receba o prêmio
\item Gere um grande número de simulações diárias para o número de vencedores. Crie uma comparação visual entre os resultados empíricos e a aproximação considerada no item 1. Descreva brevemente o que a visualização indica sobre a qualidade da aproximação
\end{enumerate}

\subsection{\textbf{SOLUÇÃO}}

\subsubsection{Item 1}

Uma aproximação válida para essa premiação é uma distribuição binominal, uma vez que para cada tentativa se escolhe um ou mais ganhadores (ou nenhum). A escolha se justifica, mesmo com os grandes números nos parâmetros, pela natureza da premiação em selecionar pessoas dentre um grande grupo. Os parâmetros dessa distribuição seriam o número de tentativas $n = 10^7$ e a probabilidade de cada pessoa ganhar $p = 10^{-7}$. Portanto, sua PMF pode ser escrita como 

\begin{equation}
P_X(k) = \begin{cases}
\binom{10^7}{k}(10^{-7}) ^k (1-10^{-7})^{10^7-k} , & \text{para } k = 0, 1, 2, \dots \\
0\ , & \text{caso contrário} \\
\end{cases}
\end{equation}

\subsubsection{Item 2}
A expressão correta para a premiação é uma distribuição de Poisson, onde intuitivamente o parâmetro é calculado pelo produto do número de pessoas com a probabilidade de cada uma ganhar, ou seja $\lambda = 10^7\times10^{-7} = 1$. Daí, essa distribuição tem valor esperado e variância igual ao parâmetro $\lambda$. Desse modo, o código em R apresentado a seguir retorna 1 para o valor esperado de ambas distribuições, uma variância de 1 para a distribuição de Poisson e uma variância de 0.9999999 para a distribuição binomial. Portanto, estes valores corroboram com a análise de que a distribuição binomial é uma boa aproximação para  a premiação da pesquisa, uma vez que se encontram muito próximos, de modo que possam ser considerados iguais para todos os efeitos. A distribuição binomial aproximada da figura \ref{fig:distb} é visualmente indistinguível da distribuição de Poisson na figura \ref{fig:distp}, exatamente como se espera a partir dos dados obtidos


\begin{lstlisting}
x <- 0:20
pmf = dpois(x, 1)


pmf2 = dbinom(x,10000000, 0.0000001)


# Valor esperado e Variância

Ex_Poisson = weighted.mean(x, pmf) # O valor esperado é uma média ponderada usando as probabilidades de pesos
cat("Valor Esperado da dist. de Poisson:", Ex_Poisson, "\n")

Ex_Binom = weighted.mean(x, pmf2) 
cat("Valor Esperado da dist. Binomial:", Ex_Binom, "\n")

cat("Variância da dist. de Poisson:", Ex_Poisson, "\n")

cat("Variância da dist. Binomial:", Ex_Binom*(1-0.0000001), "\n")
\end{lstlisting}


\begin{figure}[h]

    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=0.9\linewidth, height=6cm]{poisson.png} 
        \caption{Gráfico da PMF da distribuição de Poisson}
        \label{fig:distp}
    \end{subfigure}
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=0.9\linewidth, height=6cm]{binom.png}
        \caption{Gráfico da PMF da distribuição Binomial}
        \label{fig:distb}
    \end{subfigure}

\caption{Comparação entre a PMF da distribuição aproximada e da real}
\label{fig:image2}
\end{figure}


\subsubsection{Item 3}

A probabilidade de você receber o prêmio mesmo com outras pessoas também ganhando é dada pela Lei da Probabilidade Total. Para você receber dentre um número $i$ de ganhadores, é necessário primeiro ser selecionado para esse grupo e também ganhar dos outros $i-1$ competidores. Portanto, a probabilidade para você ser chamado para o grupo $i$ é $\frac{e^{-1}1^i}{i!}$ e a probabilidade de ganhar é $\frac{1}{i}$. Juntando ambas à Lei da Probabilidade Total: 

\[ \sum_{i=1}^{\infty} \frac{1}{e}\frac{1}{i!\times i} = \frac{1}{e}\sum_{i=1}^{\infty} \frac{1}{i!\times i} = 0.4848291\]

Este resultado é validado pelo seguinte código em R:

\begin{lstlisting}
x <- 0:20
pmf = dpois(x, 1)

# A probabilidade de você ganhar dentre os outros vencedores é dado pela lei da probabilidade total

s = 0
for(i in 1:20){
    s <- s + pmf[i+1]*(1/i)
}

cat("Probabilidade de ganhar:", s)
\end{lstlisting}

\subsubsection{Item 4}

Para uma distribuição de Poisson com 1000000 testes e $\lambda = 1$, a distribuição de probabilidades se comporta exatamente como na aproximação binomial, tendo maiores probabilidades para $k=0$ e $k=1$, fortalecendo a distribuição binomial como aproximação para esse fenômeno.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{image.png}
    \caption{Distribuição das probabilidades em uma simulação de Poisson usando um parâmetro de $\lambda = 1$}
    \label{fig:placeholder}
\end{figure}


\newpage

\section{\textbf{Questão 3}}

Você é responsável por monitorar a temperatura de uma CPU multicore em uma unidade
de processamento embarcada. Sob carga normal, a temperatura da CPU apresenta flutuações devido a mudanças na carga de trabalho, nas condições ambientais e na eficiência
do sistema de resfriamento. Testes mostram que a temperatura em regime estacionário
da CPU segue uma distribuição normal com temperatura média $\mu = 62$ ºC e desvio-padrão $\sigma = 3,5$ ºC. Sua tarefa é simular medições de temperatura da CPU e analisar suas propriedades estatísticas.

\vspace{0.5em}
\begin{enumerate}[leftmargin=*]

\item Crie uma função que gere valores com distribuição normal usando a transformação
de Box--Muller, a partir de entradas aleatórias uniformes. Especificamente:
\begin{enumerate}
  \item[(a)] Gere duas variáveis aleatórias uniformes independentes:
  \[
    U_1, U_2 \sim \mathrm{Unif}(0,1).
  \]

  \item[(b)] Calcule dois valores normais padrão usando as fórmulas de Box--Muller:
  \[
    Z_1 = \sqrt{-2\ln(U_1)}\,\cos(2\pi U_2),
    \qquad
    Z_2 = \sqrt{-2\ln(U_1)}\,\sin(2\pi U_2).
  \]
 \(Z_1\) e \(Z_2\) são variáveis aleatórias independentes com distribuição normal padrão.
Concatene-as para formar um vetor Z de valores normais padrão.

  \item[(c)] Converta cada valor normal padrão para a distribuição de temperatura da CPU:
  \[
    T = 62 + 3.5\,Z.
  \]
\end{enumerate}


\item Use seu gerador de números aleatórios para gerar 1.000 medições de temperatura da CPU. Gere mais 1.000 valores de temperatura utilizando o gerador de números aleatórios normal embutido do R, com a mesma média e desvio-padrão .

\item Para ambos os conjuntos de dados simulados, calcule:
\begin{enumerate}
  \item[(a)] Média amostral.
  \item[(b)] Desvio-padrão amostral.
  \item[(c)] Temperatura mínima e máxima observada.
  \item[(d)] Probabilidade empírica e teórica \(P(T > 68)\).
  \item[(e)] Probabilidade empírica e teórica \(P(60 < T < 65)\).
  \item[(f)] Probabilidade teórica \(P(T > 75)\).
\end{enumerate}
Algum dos conjuntos de dados simulados (1{.}000 amostras) contém valores acima
de \(75^\circ\mathrm{C}\)? Caso não, explique por que eventos raros requerem tamanhos de amostra
grandes para serem observados.

\item Visualize os resultados criando:
\begin{enumerate}
  \item[(a)] Um histograma das temperaturas simuladas da CPU (pode plotar os dois
  conjuntos de dados separadamente ou sobrepostos).
  \item[(b)] A função densidade de probabilidade (PDF) normal teórica (média \(62^\circ\mathrm{C}\),
  desvio-padrão \(3{,}5^\circ\mathrm{C}\)) sobreposta ao histograma.
\end{enumerate}

\item Discuta seus resultados respondendo às seguintes perguntas: As distribuições empíricas da temperatura da CPU se assemelham à curva normal teórica? Quão próximas estão a média amostral e o desvio-padrão amostral dos valores esperados 62 ◦C e 3, 5
◦C?
Há diferenças perceptíveis entre o conjunto de dados gerado com seu RNG manual e
o produzido pelo RNG embutido do R? Como essa simulação pode ajudar na avaliação de estratégias de resfriamento ou de escalonamento dinâmico de clock? Por que
geradores de números aleatórios uniformes são a base dos sistemas de RNG?
\end{enumerate}
\\

\subsection{Solução}
\subsubsection{Item 1 (a)}

Quando se trabalha com medições de temperatura com
distribuição normal, é necessário ter variáveis distribuidas de forma normal, que são variáveis que seguem a distribuição Normal (Gaussiana). Para isso, são criadas duas variáveis aleatórias uniformemente independentes (\(U_1\) e \(U_2\)):

\[
    U_1, U_2 \sim \mathrm{Unif}(0,1).
\]

Uma variável aleatória uniforme é aquela que todos os valores dentro de um intervalo têm a mesma probabilidade de ocorrer.

\subsubsection{Item 1 (b)}
Após a geração das duas variáveis aleatórias independentes e uniformes, usa-se do método de Box-Muller para transformá-las em variáveis aleatórias independentes com distribuição normal. As formúlas de Box-Muller são da forma:

\[
    Z_1 = \sqrt{-2\ln(U_1)}\,\cos(2\pi U_2),
    \qquad
    Z_2 = \sqrt{-2\ln(U_1)}\,\sin(2\pi U_2).
\]

Essas duas variáveis seguem a distribuição normal padrão. E para fins de facilitar a análise, \(Z_1\) e \(Z_2\) são concatenados em um vetor Z, que representa as observações seguindo a distribuição normal com média zero e variância com valor unitário.

\[
    Z_1, Z_2 \sim \mathrm{N}(0,1).
\]

\subsubsection{Item 1 (c)}
Depois de gerar o vetor Z, é necessário convertê-lo para a distribuição de temperatura da CPU: 
  \[
    T = 62 + 3.5Z ;(T = Temperatura, Z = vetor)
  \]

Veja que essa conversão é feita por uma transformação linear, onde \(62\) é a média (\(\mu\)) e \(3{,}5\) é o desvio-padrão (\(\sigma\)):

\[
    T = \mu + \sigma Z 
  \]

Sabe-se que a temperatura em regime estacionário segue uma distribuição normal com os valores acima e que a transformação linear da conversão preserva a normalidade dos dados, apenas deslocando a média de 0 para 62 e alterando os pontos devido ao desvio padrão. Assim, a nova variável aleatória T é da seguinte forma:
\[
    T \sim \mathrm{N}(62,3.5^2).
\]

Abaixo segue a função em R que gera os valores com distribuição normal usando a transformação de Box-Muller. Note que cada parte do código está informando de qual subitem ele é (item1 (a), item1 (b) ou item1 (c)).

\begin{lstlisting}
box_muller_cpu_temp <- function(n) {
  #dados sobre a temperatura (media e desvio padrao)
  mu <- 62
  sigma <- 3.5
  
  #Item 1(a): Gerar U1, U2 ~ Unif(0,1) 
  m <- ceiling(n / 2)
  U1 <- runif(m)
  U2 <- runif(m)

  #Item 1(b): Box-Muller
  Z1 <- sqrt(-2 * log(U1)) * cos(2 * pi * U2)
  Z2 <- sqrt(-2 * log(U1)) * sin(2 * pi * U2)
  Z  <- c(Z1, Z2)[1:n]

  #Item 1(c): Conversao
  T <- mu + sigma * Z
  return(T)
}
\end{lstlisting}

\subsubsection{Item 2}
Usando a função criada nos itens anteriores é possível gerar temperaturas da CPU a partir do método de Box-Muller. Assim, foram geradas 1000 medições dessa temperatura (lembre-se que nesse caso será usado média (\mu\)) = \(62^\circ\mathrm{C}\) e desvio padrão (\sigma\)) = \(3.5^\circ\mathrm{C}\)).

Além disso, também foram gerados 1000 medições usando o gerador de números aleatórios normal do próprio R, passando os mesmos parâmetros. Isso foi feito para fins de comparação, para verificar se os resultados são semelhantes. Segue abaixo o código em R:

\begin{lstlisting}
T_box <- box_muller_cpu_temp(1000)

T_rnorm <- rnorm(n = 1000, mean = 62, sd = 3.5)
\end{lstlisting}

Considere que nesse ambiente a função que gera o Box-Muller já foi criada. Um ponto muito importante é que toda vez que o código for rodado os valores gerados serão diferentes, o que pode fazer com que tenha pequenas diferenças na média, nos outros valores e nos histogramas. Para melhor compreensão do que está acontecendo no código, segue uma imagem com algumas saídas das duas formas de geração de temperaturas (Na primeira linha são valores gerados pela função Box-Muller e na segunda linha valores gerados pelo próprio R):

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{temps.JPG}
\end{figure}

Ao comparar as medições de temperatura obtidas pelo método de Box--Muller com as
geradas pelo gerador normal embutido do \textsf{R}, verifica-se que ambos os conjuntos são
consistentes com a distribuição normal assumida para o regime estacionário da CPU. Em
ambos os casos, as observações se concentram em torno da média de \(62\,^\circ\mathrm{C}\) e
apresentam dispersão compatível com o desvio-padrão de \(3{,}5\,^\circ\mathrm{C}\). Estatísticas amostrais
(média, desvio-padrão e valores mínimo e máximo) não indicam discrepâncias relevantes
entre os métodos, sugerindo que a geração usando Box--Muller reproduz adequadamente
o comportamento esperado de um gerador de variáveis normais.









\subsubsection{Item 3 (a), (b)}
Tendo gerado os 1000 dados de temperatura da CPU de duas maneiras diferentes(Pelo Box-Muller e diretamente pelo R) é possivel calcular as suas médias amostrais e seus desvios padrões.

A média amostral é a divisão entre todas as temperaturas geradas pela quantidade total de amostras, que nesse caso é 1000. Para o desvio padrão calcula-se a diferença entre cada temperatura e a média amostral, obtendo os desvios. Esses desvios são elevados, e a média deles fornecem a variância do conjunto. Por fim, tira-se a raiz quadrada da variância, resultando no desvio-padrão.

Segue abaixo o código gerador das médias amostrais e dos desvios-padrões reutilizando os valores gerados pela função Box-Muller e pelo gerador de numeros do R:

\begin{lstlisting}
#Funcao Box-Muller
mean_box <- mean(T_box)
sd_box <- sd(T_box)

#Gerador de números do R
mean_rnorm <- mean (T_rnorm)
sd_rnorm <- sd(T_rnorm)
   
\end{lstlisting}

Recapitulando, o Tbox é o vetor com os valores de temperatura gerados pelo Box-Muller e o Trnorm é o vetor com as temperaturas geradas pelo próprio R.


\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{mean.JPG}
    \caption{média amostral}
\end{figure}

\newpage

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{sd.JPG}
    \caption{desvio-padrão}
\end{figure}

A Figura 2 representa a média amostral do Box-Muller e do gerador do R, já a Figura 3 representa os desvio-padrões, também seguindo a mesma ordem. É nitido a semelhança entre os resultados, com diferença baixas entre os valores das médias e dos desvios padrões, o que indicam proximidade entre os valores gerados pelas duas formas.

\subsubsection{Item 3 (c)}
Além da média e do desvio-padrão, um dado muito importante de se obter são os valores máximos e mínimos de temperatura, pois mostra o quanto os valores gerados estão dispersos para ambos os lados.

Para isso usa-se de uma ferramenta do R. Segue abaixo o código usado:

\begin{lstlisting}
#Funcao Box-Muller
min_box <- min(T_box)
max_box <- max(T_box)

#Gerador de números do R
min_rnorm <- min(T_rnorm)
max_rnorm <- max(T_rnorm)
\end{lstlisting}

As figuras abaixo mostram os resultados obtidos de máximos e mínimos. Na primeira tem-se os máximos de temperatura e na segunda os mínimos.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{max.JPG}
    \caption{Temperatura máxima}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{min.JPG}
    \caption{Temperatura mínima}
\end{figure}

Note que na Figura 4 que mostra as temperaturas máximas quanto na Figura 5 que mostra as temperaturas mínimas, a diferença entre as duas funções foi menos de \(1^\circ\mathrm{C}\), o que mostra consistência e proximidade nos dados obtidos.

\newpage
\subsubsection{Item 3 (d),(e),(f)}
Nesse item será feito o calculo das probabilidades empíricas e teóricas de eventos diferentes usando as temperaturas da CPU. Lembre-se que o modelo das temperaturas segue uma distribuição normal com média (\mu\)) = \(62^\circ\mathrm{C}\) e desvio-padrão (\sigma\)) = \(3.5^\circ\mathrm{C}\).

Como se trata de uma distribuição normal , usaremos do resultado da transformação que nos fornece o Z, que seus valores de probabilidade são baseados em uma tabela de relacionada valores de probabilidades fixas (é possível encontrar essa tabela no final do arquivo).

\[
Z = \frac{X - \mu}{\sigma}
\]

Z é o resultado da transformação, \mu\) é a média amostral e \sigma\) é o desvio-padrão.

Além disso, para calcular os valores empíricos e teóricos, é necessário reutilizar os códigos fornecidos dos Itens 1 e 2 e 3 (a)(b)(c). Eles podem ser encontrados no apêndice ao final do arquivo.
\vspace{0.5cm}

\subtitle{\textbf{(d) - P(T > 68):}}
A probabilidade empírica é obtida diretamente a partir dos dados gerados, sendo calculada como a proporção de observações de temperatura que excedem \(68\,^\circ\mathrm{C}\)
em relação ao número total de amostras. Em termos práticos, conta-se quantos valores do conjunto  satisfazem a condição \(T > 68\) e divide-se esse número pelo total de observações.

Já a probabilidade teórica é determinada assumindo que a temperatura da CPU segue uma
distribuição normal com média \(\mu = 62\) e desvio-padrão \(\sigma = 3{,}5\). Nesse caso, a
probabilidade \(P(T > 68)\) é calculada a partir da função de distribuição acumulada da
normal, após a padronização da variável mostrada acima (o valor Z). 

Segue abaixo  o código feito em R e sua saída (Figura 8) com os valores desejados de probabilidades:

\begin{lstlisting}
#valores empiricos
prob_emp_box_D <- mean(T_box > 68)
prob_emp_rnorm_D <- mean(T_rnorm > 68)

#valores teoricos (vale para os dois)
prob_teo_D <- 1 - pnorm(68,mean = 62,sd = 3.5)   
\end{lstlisting}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{prob1.JPG}
    \caption{P(T > 68)}
\end{figure}

Utilizando a fórmula da transformação citada anteriormente é possivel calcular o resultado teórico e mostrar que os valores obtidos são extremamente pertos:
\[
Z = \frac{68 - 62}{3{,}5} \approx 1{,}71
\]
Assim, 
\[
P(T > 68) = P(Z > 1{,}71) = 1 - \Phi(1{,}71) \approx 0{,}043
\]

\vspace{0.5cm}

\subtitle{\textbf{(e) - P(60 < T < 65):}}
A probabilidade empírica é estimada a partir dos dados simulados, calculando-se a fração
de observações cuja temperatura está estritamente entre \(60\,^\circ\mathrm{C}\) e
\(65\,^\circ\mathrm{C}\). Esse procedimento consiste em contar o número de amostras que
satisfazem a condição \(60 < T < 65\) e dividir esse total pelo número de medições
realizadas.

Por outro lado, a probabilidade teórica é obtida assumindo que a variável aleatória
\(T\) segue uma distribuição normal com média \(\mu = 62\) e desvio-padrão
\(\sigma = 3{.}5\). Nesse contexto, a probabilidade desejada é expressa como
\[
P(60 < T < 65) = F_T(65) - F_T(60),
\]
onde \(F_T(\cdot)\) representa a função de distribuição acumulada da normal.

Segue abaixo  o código feito em R e sua saída (Figura 9) com os valores desejados de probabilidades:

\begin{lstlisting}
#valores empiricos
prob_emp_box_E <- mean(T_box > 60 & T_box < 65)
prob_emp_rnorm_E <- mean(T_rnorm > 60 & T_rnorm < 65)

#valores teoricos (vale para os dois)
prob_teo_E <- pnorm(65,mean = 62,sd = 3.5) - pnorm (60,mean = 62,sd = 3.5)
\end{lstlisting}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{prob2.JPG}
    \caption{P(60 < T < 65)}
\end{figure}

Para o cálculo teórico dessa probabilidade, a variável aleatória \(T\) é
padronizada utilizando a transformação da distribuição normal, substituindo \(\mu = 62\,^\circ\mathrm{C}\) e \(\sigma = 3{,}5\,^\circ\mathrm{C}\), obtêm-se os valores
padronizados aos limites do intervalo:
\[
Z_1 = \frac{60 - 62}{3{,}5} \approx -0{,}57,
\qquad
Z_2 = \frac{65 - 62}{3{,}5} \approx 0{,}86.
\]
Assim,
\[
P(60 < T < 65) = P(-0{,}57 < Z < 0{,}86) = \Phi(0{,}86) - \Phi(-0{,}57) \approx 0{,}52.
\]
\newpage

\vspace{0.5cm}

\subtitle{\textbf{(f) - P(T > 75):}}
Para a probabilidade empírica \(P(T > 75)\), utiliza se o conjunto de dados simulados. Nesse caso, a probabilidade é calculada como a razão entre
o número de observações cuja temperatura excede \(75\,^\circ\mathrm{C}\) e o total de amostras
geradas. Em termos práticos, verifica-se quantos valores do vetor de temperaturas
simuladas satisfazem a condição \(T > 75\) e divide-se esse número pelo total de
1{.}000 medições.

Devido ao fato de \(75\,^\circ\mathrm{C}\) estar a vários desvios-padrão acima da média
\(\mu = 62\,^\circ\mathrm{C}\), a probabilidade teórica associada a esse evento é extremamente
baixa. Assim, é comum que, em amostras de tamanho limitado, como 1{.}000 observações,
nenhum valor ultrapasse esse limiar. Esse resultado empírico reforça a ideia de que
eventos raros exigem tamanhos de amostra significativamente grandes para serem
observados.

Segue abaixo  o código feito em R e sua saída (Figura 10) com os valores desejados de probabilidades:

\begin{lstlisting}
#valores empiricos
p_emp_box_F   <- mean(T_box > 75)
p_emp_rnorm_F <- mean(T_rnorm > 75)

#valores teoricos (vale para os dois)
p_teo_F <- 1 - pnorm(75, mean = 62, sd = 3.5)
\end{lstlisting}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{prob3.JPG}
    \caption{P(60 < T < 65)}
\end{figure}

Para o cálculo teórico da probabilidade \(P(T > 75)\), a variável aleatória \(T\) é padronizada
por meio da transformação da normal padrão, substituindo \(\mu = 62\,^\circ\mathrm{C}\), \(\sigma = 3{,}5\,^\circ\mathrm{C}\) e \(T = 75\,^\circ\mathrm{C}\), tem-se:
\[
Z = \frac{75 - 62}{3{,}5} \approx 3{,}71.
\]
Assim,
\[
P(T > 75) = P(Z > 3{,}71) = 1 - \Phi(3{,}71) \approx 0{,}0001.
\]

Note que na Figura 10, os valores de probabilidades empíricas foram zero, isso diz que nenhuma temperatura gerada ultrapassou 75.

\textbf{Algum dos conjuntos de dados simulados (1.000 amostras) contém valores acima
de 75◦C?} Com base nos resultados obtidos, observa-se que nenhum dos conjuntos de dados simulados
com amostras apresentou valores de temperatura acima de \(75\,^\circ\mathrm{C}\). Em
particular, as probabilidades empíricas estimadas a partir dos dados gerados pelo método
de Box--Muller e pelo gerador normal embutido do R foram ambas iguais a zero.

Por outro lado, o cálculo teórico indica que a probabilidade de ocorrência de temperaturas
acima de \(75\,^\circ\mathrm{C}\) é extremamente baixa,
\[
p_{\text{teo}} = P(T > 75) \approx 0{,}0001019.
\]

Esses resultados ilustram que eventos raros, caracterizados por probabilidades muito
pequenas, exigem tamanhos de amostra significativamente maiores para serem observados
empiricamente com frequência apreciável. Em amostras relativamente pequenas, como no
caso de \(1{.}000\) observações, é comum que tais eventos simplesmente não ocorram,
mesmo quando sua probabilidade teórica é não nula.


\subsubsection{Item 4 (a)}
Para melhor analisar os dados obtidos, foram construídos dois histogramas das temperaturas
simuladas da CPU, utilizando tanto os dados gerados pelo método de Box--Muller quanto
aqueles obtidos pelo gerador normal do R. Os histogramas são importantes para 
avaliar a distribuição empírica das observações, evidenciando a concentração dos valores
em torno da média e a dispersão característica do conjunto de dados.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{hist1.JPG}
    \caption{Histogramas das temperaturas simuladas da CPU}
\end{figure}

Na Figura 11, o histograma da esquerda representa aquele gerado pelas amostras da função Box-Muller e o da direita é o gerado pelas amostras da função de geração de números do R. Veja que nos dois os valores de concentram perto da média (62), o que está de acordo com o que já foi discutido anteriormente, mostrando assim uma distribuição normal dos valores.

\subsubsection{Item 4 (b)}

Para comparar a distribuição empírica das temperaturas simuladas com o modelo
probabilístico assumido, sobrepõe-se ao histograma a função densidade de probabilidade
(PDF) teórica da normal com média \(\mu = 62\,^\circ\mathrm{C}\) e desvio-padrão
\(\sigma = 3{,}5\,^\circ\mathrm{C}\). Como o histograma é plotado na escala de densidade
(probabilidade), a curva pode ser desenhada diretamente no mesmo gráfico,
permitindo verificar visualmente a proximidade entre as amostras simuladas e a
distribuição normal teórica. Abaixo, a Figura 12 ilustra exatamente a semelhança entre a angulação da curva do PDF e do histograma, sendo na esquerda a da função Box-Muller e na direita a gerada pelas amostras da função de geração de números do R.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{hist2.JPG}
    \caption{Histogramas das temperaturas simuladas da CPU com PDF}
\end{figure}

Os códigos dos histogramas e da curva da PDF se encontram no apêncice no final do arquivo, onde também se encontra o código completo do exercício 3.
\newpage
\subsubsection{Item 5}
As distribuições de temperatura da CPU geradas por simulação seguem consistentemente o perfil da curva normal teórica, como mostram os histogramas e estatísticas descritivas. Em todos os conjuntos, os valores se concentram em torno da média, com dispersão compatível com o formato simétrico esperado.

As médias amostrais obtidas nas simulações apresentam valores muito próximos da expectativa teórica de 62, enquanto os desvios-padrão amostrais são coerentes com o parâmetro teórico de 3{,}5. Pequenas discrepâncias entre os valores amostrais e teóricos são esperadas devido à variabilidade da amostra, mas não comprometem a validade do modelo probabilístico adotado.

Não foram identificadas diferenças significativas entre o conjunto de dados gerado pelo método manual baseado na transformação de Box–Muller e aquele produzido pelo gerador normal do R. Ambos os métodos produzem distribuições estatisticamente equivalentes, indicando que a implementação do gerador manual é adequada e confiável para a geração de variáveis aleatórias normais.

Esse tipo de abordagem simulacional é particularmente útil para a avaliação de estratégias de resfriamento e de escalonamento dinâmico de clock, pois permite estimar probabilidades de ocorrência de temperaturas elevadas e analisar o comportamento térmico do sistema sob diferentes condições operacionais — inclusive sob variações de clock — tudo isso antes mesmo da implementação física em hardware real.

Por fim, é importante destacar que geradores de números aleatórios uniformes constituem a base fundamental dos sistemas de geração de números aleatórios, pois são mais simples de implementar e podem ser transformados matematicamente para produzir variáveis com distribuições mais complexas, como a normal. Métodos como a transformação de Box–Muller exemplificam precisamente como sequências uniformes podem ser convertidas eficientemente em distribuições normais, atendendo às necessidades de simulações estatísticas avançadas e aplicações práticas de engenharia.
























\newpage
\section{\textbf{Apêndice - Códigos em R}}

\subsection{Exercício 1:}

\begin{lstlisting}
   
# Distribuição binomial com n=50 e p=0.7

x <- 0:50

pmf = dbinom(x, 50, 0.7) # Função da PMF (51 valores, então pmf[1] = 0 e P(X = x) = pmf[x+1])       

plot(x,pmf,type='h',col='red',lwd=2, # Gráfico da PMF
     xlab= 'x', ylab='P(x)')

abline(h=0) # Adiciona uma linha no valor de P(x) = 0 para aumentar a legibilidade


cdf = c(0, cumsum(pmf)) # Calculando a CDF a partir da PMF

plot(cdf ,type='h',col='blue',lwd=2, # Gráfico da CDF
     xlab= 'x', ylab='P(X <= x)')

abline(h=0) # Adiciona uma linha no valor de P(x) = 0 para aumentar a legibilidade



# O valor esperado de uma distribuição binomial é n*p, nesse caso sendo 50*0.7 = 35.

Ex = weighted.mean(x, pmf) # O valor esperado é uma média ponderada usando as probabilidades de pesos
cat("Valor Esperado:", Ex, "\n")

# A variância de uma distribuição binomial é n*p*(1-p), nesse caso sendo 50*0.7*0.3 = 10.5

Var = Ex*0.3
dp = sqrt(Var)
cat("Variância:", Var, "\n")

cat("Desvio-Padrão:", sqrt(Var), "\n")

# Para X>=20:
s = 0
for(i in 21:50){
  s <- s + pmf[i]
}
cat("P(X >= 20):", s, "\n")



# Para 30 < X < 43:
s = 0
for(i in 32:43){
  s <- s + pmf[i]
}
cat("P(30 < X < 43):", s, "\n")

# Para X = 31:


cat("P(X = 31):", pmf[32], "\n")


\end{lstlisting}

\subsection{Exercício 2:}

\begin{lstlisting}
# Como temos uma baixíssima probabilidade e um grande número de pessoas, pode-se modelar essa pesquisa como uma distribuição de Poisson. Além disso, como temos p = 10^-7 e n = 10^7, intuitivamente o número de pessoas que ganhariam o prêmio em um dia seria 10^7*10^-7 = 1 pessoa. Portanto, o parâmetro dessa distribuição seria 1.

x <- 0:20
pmf = dpois(x, 1)

# Veja também que podemos modelar esse prêmio como sendo uma distribuição binomial, bem mais simples. Isso ocorre porque o valor do número de tentativas (n) da distribuição binomial é muito grande. Portanto, isso faz com que a distribuição binomial tenda a se distribuir como uma de Poisson.

pmf2 = dbinom(x,10000000, 0.0000001)

plot(x,pmf,type='h',col='red',lwd=2,
        xlab= 'x', ylab='P(x)')
points(x,pmf, pch=19, col='red')

abline(h=0) # Adiciona uma linha no valor de P(x) = 0 para aumentar a legibilidade

plot(x,pmf2,type='h',col='blue',lwd=2,
        xlab= 'x', ylab='P(x)')
points(x,pmf2, pch=19, col='blue')

abline(h=0) # Adiciona uma linha no valor de P(x) = 0 para aumentar a legibilidade


# Valor esperado e Variância

Ex_Poisson = weighted.mean(x, pmf) # O valor esperado é uma média ponderada usando as probabilidades de pesos
cat("Valor Esperado da dist. de Poisson:", Ex_Poisson, "\n")

Ex_Binom = weighted.mean(x, pmf2) 
cat("Valor Esperado da dist. Binomial:", Ex_Binom, "\n")

cat("Variância da dist. de Poisson:", Ex_Poisson, "\n")

cat("Variância da dist. Binomial:", Ex_Binom*(1-0.0000001), "\n")


# A probabilidade de você ganhar dentre os outros vencedores é dado pela lei da probabilidade total

s = 0
for(i in 1:20){
    s <- s + pmf[i+1]*(1/i)
}

cat("Probabilidade de ganhar:", s)


y = rpois(1000000, 1)

hist(y, prob = TRUE, breaks = 9, border = 'black', right = FALSE,
    main = " ")
\end{lstlisting}

\subsection{Exercício 3:}

\begin{lstlisting}

box_muller_cpu_temp <- function(n){
  #dados sobre a temperatura (media e desvio padrao)
  mu <- 62
  sigma <- 3.5
  
  #Item 1(a)
  m <- ceiling(n / 2)
  U1 <- runif(m)
  U2 <- runif(m)
  
  #Item 1(b): Box-Muller
  Z1 <- sqrt(-2 * log(U1)) * cos(2 * pi * U2)
  Z2 <- sqrt(-2 * log(U1)) * sin(2 * pi * U2)
  Z  <- c(Z1, Z2)[1:n]
  
  #Item 1(c): Conversao
  T <- mu + sigma * Z
  return(T)
}

T_box <- box_muller_cpu_temp(1000)

T_rnorm <- rnorm(n = 1000, mean = 62, sd = 3.5)

mean_box <- mean(T_box)
sd_box <- sd(T_box)

mean_rnorm <- mean (T_rnorm)
sd_rnorm <- sd(T_rnorm)

min_box <- min(T_box)
max_box <- max(T_box)


min_rnorm <- min(T_rnorm)
max_rnorm <- max(T_rnorm)

#valores empiricos
prob_emp_box_D <- mean(T_box > 68)
prob_emp_rnorm_D <- mean(T_rnorm > 68)

#valores teoricos (vale para os dois)
prob_teo_D <- 1 - pnorm(68,mean = 62,sd = 3.5)

#valores empiricos
prob_emp_box_E <- mean(T_box > 60 & T_box < 65)
prob_emp_rnorm_E <- mean(T_rnorm > 60 & T_rnorm < 65)

#valores teoricos (vale para os dois)
prob_teo_E <- pnorm(65,mean = 62,sd = 3.5) - pnorm (60,mean = 62,sd = 3.5)

#valores empiricos
p_emp_box_F   <- mean(T_box > 75)
p_emp_rnorm_F <- mean(T_rnorm > 75)

#valores teoricos (vale para os dois)
p_teo_F <- 1 - pnorm(75, mean = 62, sd = 3.5)

par(mfrow = c(1, 2))

#Box-Muller
hist(T_box, breaks = 30,
     main = "Temperaturas simuladas (Box-Muller)",
     xlab = "Temperatura (°C)")

#Gerador do R
hist(T_rnorm, breaks = 30,
     main = "Temperaturas simuladas (rnorm)",
     xlab = "Temperatura (°C)")

# Item 4(b): PDF normal teórica sobreposta ao histograma
# (assumindo que já existe um vetor de temperaturas T: use T_box ou T_rnorm)

mu <- 62
sigma <- 3.5

hist(T_box, breaks = 30, probability = TRUE,
     main = "Box-Muller + PDF teórica",
     xlab = "Temperatura (°C)")
curve(dnorm(x, mean = mu, sd = sigma), add = TRUE, lwd = 2)

hist(T_rnorm, breaks = 30, probability = TRUE,
     main = "rnorm + PDF teórica",
     xlab = "Temperatura (°C)")
curve(dnorm(x, mean = mu, sd = sigma), add = TRUE, lwd = 2)

\end{lstlisting}

\subsection{Probabilidades - distruição normal:}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\linewidth]{WhatsApp-Image-2022-05-31-at-13.15.07.jpeg}
    \caption{}
\end{figure}


\end{document}
